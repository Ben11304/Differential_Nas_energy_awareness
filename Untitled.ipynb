{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b1b137-d2be-4f2c-b63d-7a255579bfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/cnn/train_search.py\", line 18, in <module>\n",
      "    from model_search import Network\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/cnn/model_search.py\", line 4, in <module>\n",
      "    from operations import *\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/cnn/operations.py\", line 3, in <module>\n",
      "    import snntorch as snn\n",
      "ModuleNotFoundError: No module named 'snntorch'\n"
     ]
    }
   ],
   "source": [
    "!python train_search.py --device cuda:1 --learning_rate 0.01 --snn_step 5 --epochs 5 --layers 3 --arch_learning_rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d25069-9e74-4629-bd51-80ed4e0ed8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/cnn/train_search.py\", line 18, in <module>\n",
      "    from model_search import Network\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/cnn/model_search.py\", line 4, in <module>\n",
      "    from operations import *\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/cnn/operations.py\", line 3, in <module>\n",
      "    import snntorch as snn\n",
      "ModuleNotFoundError: No module named 'snntorch'\n"
     ]
    }
   ],
   "source": [
    "!python train_search.py --batch_size 16 --epochs 16 --device cuda:0 --learning_rate 0.01 --arch_learning_rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e553e429-ffb2-47d7-8ad5-2963e9060bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_binhnguyen/Nas/darts/cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_binhnguyen/Nas/darts_env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd darts/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc3d390-9f0e-4474-9c8b-f0c55883728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/24 03:04:17 PM Using device: cuda:1\n",
      "108 108 36\n",
      "108 144 36\n",
      "144 144 36\n",
      "144 144 72\n",
      "144 288 72\n",
      "288 288 72\n",
      "288 288 144\n",
      "288 576 144\n",
      "576 576 144\n",
      "576 576 144\n",
      "/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA GeForce RTX 3080 Ti with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
      "/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA GeForce RTX 4060 with CUDA capability sm_89 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 4060 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
      "04/24 03:04:18 PM Epoch 0: Learning Rate 0.010000\n",
      "[Train Epoch 0]:   0%|                                  | 0/313 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/loopup_create/cnn/train.py\", line 275, in <module>\n",
      "    main()\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/loopup_create/cnn/train.py\", line 134, in main\n",
      "    train_loss = train(train_loader, model, criterion, optimizer, device, epoch)\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/loopup_create/cnn/train.py\", line 187, in train\n",
      "    logits, _ = model(x)\n",
      "  File \"/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/jupyter-iec_binhnguyen/Nas/darts/loopup_create/cnn/model.py\", line 275, in forward\n",
      "    s0 = s1 = self.stem(x)\n",
      "  File \"/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py\", line 148, in forward\n",
      "    self.num_batches_tracked.add_(1)  # type: ignore[has-type]\n",
      "RuntimeError: CUDA error: no kernel image is available for execution on the device\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --batch_size 16 --epochs 30 --gpu 1 --learning_rate 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe678c25-320f-47b3-9d3e-fd33f20ec669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/13 12:29:55 AM args = Namespace(data='../data', batch_size=4, learning_rate=0.01, learning_rate_min=0.001, snn_step=5, momentum=0.9, weight_decay=0.0003, report_freq=50, device='cuda:1', epochs=16, init_channels=16, layers=3, model_path='saved_models', cutout=False, cutout_length=16, drop_path_prob=0.3, save='./log/', seed=2, grad_clip=5, train_portion=0.5, unrolled=False, arch_learning_rate=0.001, arch_weight_decay=0.001)\n",
      "04/13 12:29:55 AM param size = 1.028682MB\n",
      "/home/jupyter-iec_binhnguyen/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "04/13 12:29:55 AM epoch 0 lr 9.913534e-03\n",
      "04/13 12:29:55 AM genotype = Genotype(normal=[('avg_pool_3x3', 1), ('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('skip_connect', 0), ('sep_conv_5x5', 2), ('avg_pool_3x3', 1), ('avg_pool_3x3', 1), ('avg_pool_3x3', 0)], normal_concat=range(2, 6), reduce=[('dil_conv_5x5', 0), ('snn_multistep_3x3', 1), ('snn_multistep_5x5', 1), ('snn_multistep_3x3', 0), ('avg_pool_3x3', 1), ('skip_connect', 3), ('max_pool_3x3', 3), ('dil_conv_5x5', 2)], reduce_concat=range(2, 6))\n",
      "04/13 12:29:55 AM tensor([[0.1000, 0.1000, 0.1001, 0.1000, 0.1000, 0.1000, 0.0998, 0.1000, 0.1000,\n",
      "         0.1000],\n",
      "        [0.1001, 0.1000, 0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0998,\n",
      "         0.1001],\n",
      "        [0.1000, 0.0999, 0.1000, 0.1002, 0.1001, 0.0998, 0.0999, 0.1001, 0.1000,\n",
      "         0.1000],\n",
      "        [0.0998, 0.1001, 0.1000, 0.0999, 0.1000, 0.1002, 0.0999, 0.1000, 0.1001,\n",
      "         0.1000],\n",
      "        [0.1001, 0.1000, 0.1000, 0.1001, 0.0999, 0.0999, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000],\n",
      "        [0.1001, 0.1000, 0.0999, 0.0999, 0.1001, 0.1000, 0.0999, 0.1001, 0.1001,\n",
      "         0.0999],\n",
      "        [0.1000, 0.1001, 0.1001, 0.0999, 0.1000, 0.1000, 0.1000, 0.1001, 0.0999,\n",
      "         0.0999],\n",
      "        [0.0999, 0.0998, 0.1000, 0.0999, 0.1001, 0.1002, 0.1002, 0.1000, 0.0999,\n",
      "         0.0999],\n",
      "        [0.1001, 0.1000, 0.1000, 0.0999, 0.1000, 0.1000, 0.1001, 0.1000, 0.1000,\n",
      "         0.0999],\n",
      "        [0.0999, 0.1001, 0.1002, 0.1000, 0.1001, 0.0999, 0.1000, 0.0999, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1000, 0.1000, 0.1002, 0.0999, 0.1000, 0.1001, 0.0999, 0.0999, 0.0999,\n",
      "         0.1000],\n",
      "        [0.0998, 0.0999, 0.1000, 0.1001, 0.1001, 0.0999, 0.0999, 0.1001, 0.1001,\n",
      "         0.1001],\n",
      "        [0.0999, 0.0999, 0.0999, 0.0999, 0.1001, 0.1001, 0.1001, 0.1001, 0.1000,\n",
      "         0.0999],\n",
      "        [0.1001, 0.1001, 0.1001, 0.0998, 0.1002, 0.1000, 0.1000, 0.0998, 0.0999,\n",
      "         0.1001]], device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "04/13 12:29:55 AM tensor([[0.1002, 0.1001, 0.0998, 0.0998, 0.1001, 0.1001, 0.1000, 0.1001, 0.1000,\n",
      "         0.0998],\n",
      "        [0.0999, 0.1001, 0.0999, 0.1000, 0.1001, 0.1000, 0.0998, 0.1000, 0.1001,\n",
      "         0.1000],\n",
      "        [0.0999, 0.0999, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1001, 0.1001,\n",
      "         0.1000],\n",
      "        [0.0998, 0.1000, 0.1001, 0.0999, 0.1000, 0.0999, 0.1001, 0.1001, 0.1001,\n",
      "         0.1002],\n",
      "        [0.1000, 0.1001, 0.1001, 0.0999, 0.1000, 0.0999, 0.1000, 0.1001, 0.1001,\n",
      "         0.1000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000],\n",
      "        [0.1000, 0.1000, 0.1002, 0.0999, 0.1001, 0.1000, 0.1001, 0.1000, 0.0999,\n",
      "         0.0998],\n",
      "        [0.1001, 0.0999, 0.1000, 0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.0999,\n",
      "         0.1000],\n",
      "        [0.1000, 0.1000, 0.1002, 0.1002, 0.1000, 0.1000, 0.0999, 0.0999, 0.1000,\n",
      "         0.1000],\n",
      "        [0.1002, 0.0999, 0.1001, 0.0998, 0.0999, 0.1001, 0.0999, 0.1001, 0.1001,\n",
      "         0.0999],\n",
      "        [0.1000, 0.0999, 0.1000, 0.1001, 0.1000, 0.0999, 0.1001, 0.0998, 0.0999,\n",
      "         0.1002],\n",
      "        [0.1000, 0.0999, 0.0999, 0.1000, 0.0999, 0.0999, 0.1001, 0.1002, 0.1000,\n",
      "         0.1001],\n",
      "        [0.1000, 0.1002, 0.1000, 0.1002, 0.0999, 0.1000, 0.1000, 0.0997, 0.1001,\n",
      "         0.0999],\n",
      "        [0.1000, 0.1000, 0.0999, 0.1000, 0.1000, 0.1000, 0.1000, 0.0998, 0.1000,\n",
      "         0.1001]], device='cuda:1', grad_fn=<SoftmaxBackward0>)\n",
      "[Train]:   7%| | 46/625 [00:36<07:39,  1.26it/s, loss_task=0.749, mIoU=0.0422, m"
     ]
    }
   ],
   "source": [
    "!python train_search.py --batch_size 4 --epochs 8 --device cuda:0 --learning_rate 0.1 --arch_learning_rate 0.01 --layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3567189-b8d4-4e9a-99f2-c654c517809d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nas",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
